{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do:\n",
    "\n",
    "- build dataset\n",
    "- test `AcousticDatafile(test.wav)` and `segments` method\n",
    "- test `AcousticDataset(directory)` and `segments` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnnseg.data import AcousticDatafile, AcousticDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:/model/german/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [x[:-4] for x in os.listdir() if x.endswith(\".wav\")][:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de2_e_b01_v0102301011111',\n",
       " 'de2_e_b01_v0102301011112',\n",
       " 'de2_e_b01_v0102301011113',\n",
       " 'de2_e_b01_v0102301011114',\n",
       " 'de2_e_b01_v0102301011115',\n",
       " 'de2_e_b01_v0102301011116',\n",
       " 'de2_e_b01_v0102301011117']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing file \"de2_e_b...\" 7/7       |    ETA - 0s     \n"
     ]
    }
   ],
   "source": [
    "dataset = AcousticDataset(\"D:/tests/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving issue in .inputs and .targets methods inside AcousticDataset class.\n",
    "Notes: `.inputs` and `.targets` only call `.segment_and_stack`, once as `padding = 'pre'` and once `padding = 'post'`\n",
    "# To do:\n",
    "- test `.segment_and_stack`from `AcousticDataset` outside of script \n",
    "- test `.inputs` and `.targets` outside of script\n",
    "- UNDERSTAND what this does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using method .targets from AcousticDataset\n",
      "\n",
      " ####### using method .segment_and_stack from AcousticDataset ###### \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATASET \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "reverse = True \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = False \n",
      "\n",
      "resample = None \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATAFILE: \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "padding = post \n",
      "\n",
      "reverse = True \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = False \n",
      "\n",
      "resample = None \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], shape=(8, 0, 13), dtype=float64),\n",
       " array([], shape=(8, 0), dtype=float64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ####### using method .segment_and_stack from AcousticDataset ###### \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATASET \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "reverse = False \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = True \n",
      "\n",
      "resample = None \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATAFILE: \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "padding = pre \n",
      "\n",
      "reverse = False \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = True \n",
      "\n",
      "resample = None \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 43510 and the array at index 1 has size 56370",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4e6146236ffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegment_and_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\model\\dnnseg\\data.py\u001b[0m in \u001b[0;36msegment_and_stack\u001b[1;34m(self, segments, max_len, padding, reverse, normalize, center, with_deltas, resample)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 43510 and the array at index 1 has size 56370"
     ]
    }
   ],
   "source": [
    "dataset.segment_and_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ####### using method .inputs from AcousticDataset ###### \n",
      "\n",
      "\n",
      " ####### using method .segment_and_stack from AcousticDataset ###### \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATASET \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "reverse = False \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = True \n",
      "\n",
      "resample = None \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATAFILE: \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "padding = pre \n",
      "\n",
      "reverse = False \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = True \n",
      "\n",
      "resample = None \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 43510 and the array at index 1 has size 56370",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-eb84b47ad76b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\model\\dnnseg\\data.py\u001b[0m in \u001b[0;36minputs\u001b[1;34m(self, segments, max_len, padding, reverse, normalize, center, resample)\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[0mcenter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 785\u001b[1;33m             \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    786\u001b[0m         )\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\model\\dnnseg\\data.py\u001b[0m in \u001b[0;36msegment_and_stack\u001b[1;34m(self, segments, max_len, padding, reverse, normalize, center, with_deltas, resample)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 43510 and the array at index 1 has size 56370"
     ]
    }
   ],
   "source": [
    "dataset.inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = dataset.data[\"de2_e_b01_v0102301011114\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-4.3935999e+02,  3.8676880e+01,  4.1746397e+00, ...,\n",
       "          -1.3803151e+00, -7.7529901e-01,  1.0259549e-01],\n",
       "         [-4.3328519e+02,  5.8681412e+01,  1.4759262e+01, ...,\n",
       "          -1.0292969e+00, -1.0466719e+00,  4.4414034e-01],\n",
       "         [-4.0103995e+02,  8.3274643e+01,  2.6987366e+01, ...,\n",
       "           6.4401424e-01,  8.8818264e-01,  5.4182857e-01],\n",
       "         ...,\n",
       "         [-3.7044510e+02,  1.0567401e+02,  3.3955765e+01, ...,\n",
       "           1.0104920e-01, -1.5401207e-01,  5.6449831e-01],\n",
       "         [-3.7411316e+02,  9.9037827e+01,  3.1980671e+01, ...,\n",
       "          -5.0408220e-01,  1.0673784e-01,  9.2395109e-01],\n",
       "         [-3.8897562e+02,  9.1623596e+01,  3.5974098e+01, ...,\n",
       "          -9.9924690e-01,  3.4237463e-02,  3.6131066e-01]]], dtype=float32),\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile.segment_and_stack(padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-4.3935999e+02,  3.8676880e+01,  4.1746397e+00, ...,\n",
       "          -1.3803151e+00, -7.7529901e-01,  1.0259549e-01],\n",
       "         [-4.3328519e+02,  5.8681412e+01,  1.4759262e+01, ...,\n",
       "          -1.0292969e+00, -1.0466719e+00,  4.4414034e-01],\n",
       "         [-4.0103995e+02,  8.3274643e+01,  2.6987366e+01, ...,\n",
       "           6.4401424e-01,  8.8818264e-01,  5.4182857e-01],\n",
       "         ...,\n",
       "         [-3.7044510e+02,  1.0567401e+02,  3.3955765e+01, ...,\n",
       "           1.0104920e-01, -1.5401207e-01,  5.6449831e-01],\n",
       "         [-3.7411316e+02,  9.9037827e+01,  3.1980671e+01, ...,\n",
       "          -5.0408220e-01,  1.0673784e-01,  9.2395109e-01],\n",
       "         [-3.8897562e+02,  9.1623596e+01,  3.5974098e+01, ...,\n",
       "          -9.9924690e-01,  3.4237463e-02,  3.6131066e-01]]], dtype=float32),\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile.segment_and_stack(padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`segment_and_stack` method from AcousticDatafile"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    def segment_and_stack(\n",
    "            self,\n",
    "            segments='wrd',\n",
    "            max_len=None,\n",
    "            padding='pre',\n",
    "            reverse=False,\n",
    "            normalize=False,\n",
    "            center=False,\n",
    "            with_deltas=True,\n",
    "            resample=None\n",
    "    ):\n",
    "        assert not (normalize and center), 'normalize and center cannot both be true, since normalize constrains to the interval [0,1] and center recenters at 0.'\n",
    "        if isinstance(segments, str):\n",
    "        \n",
    "            if segments == 'vad':\n",
    "                segments_arr = self.vad_segments\n",
    "            elif segments == 'wrd':\n",
    "                segments_arr = self.wrd_segments\n",
    "            elif segments == 'phn':\n",
    "                segments_arr = self.phn_segments\n",
    "            elif segments == 'rnd':\n",
    "                segments_arr = self.rnd_segments\n",
    "            else:\n",
    "                raise ValueError('Segment type \"%s\" not recognized.' % segments)\n",
    "        else:\n",
    "            segments_arr = segments\n",
    "\n",
    "        #print(f\"Step 1: segments_arr is {segments_arr}\")\n",
    "\n",
    "        pad_seqs = padding not in ['None', None]\n",
    "\n",
    "        bounds = np.array(\n",
    "            np.rint((segments_arr[['start', 'end']] * 1000 / self.offset)),\n",
    "            dtype=np.int32\n",
    "        )\n",
    "\n",
    "        #print(f\"Step 2: boudnds is {bounds}\")\n",
    "        feats_split = []\n",
    "        mask_split = []\n",
    "        for i in range(len(bounds)):\n",
    "            s = bounds[i, 0]\n",
    "            e = bounds[i, 1]\n",
    "            if max_len is not None:\n",
    "                e = min(e, s + max_len)\n",
    "            new_feats = self.feats[s:e, :]\n",
    "            length = e - s\n",
    "            if resample and new_feats.shape[0] > 0:\n",
    "                length = resample\n",
    "                new_feats = scipy.signal.resample(new_feats, resample, axis=0)\n",
    "\n",
    "            if not with_deltas:\n",
    "                new_feats = new_feats[:, :self.n_coef]\n",
    "\n",
    "            if normalize:\n",
    "                maximum = new_feats.max()\n",
    "                minimum = new_feats.min()\n",
    "                diff = maximum - minimum\n",
    "                new_feats = (new_feats - minimum) / diff\n",
    "            if center:\n",
    "                new_feats = new_feats - new_feats.mean()\n",
    "\n",
    "            if not pad_seqs:\n",
    "                new_feats = new_feats[None, ...]\n",
    "                mask = np.ones((1, length))\n",
    "            else:\n",
    "                mask = np.ones(length)\n",
    "\n",
    "            feats_split.append(new_feats)\n",
    "            mask_split.append(mask)\n",
    "\n",
    "        if pad_seqs:\n",
    "            feats = pad_sequence(feats_split, padding=padding, reverse=reverse)\n",
    "            mask = pad_sequence(mask_split, padding=padding, reverse=reverse)\n",
    "        else:\n",
    "            feats = feats_split\n",
    "            mask = mask_split\n",
    "\n",
    "        return feats, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments passed during fitting:\n",
    "```\n",
    "segments = \"wrd\",\n",
    "max_len = 50,\n",
    "padding = \"pre\",\n",
    "reverse = False,\n",
    "normalize = False,\n",
    "center = True,\n",
    "with_deltas = True,\n",
    "resample = None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_arr = datafile.wrd_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de2_e_b01_v0102301011114</td>\n",
       "      <td>524.4</td>\n",
       "      <td>939.798</td>\n",
       "      <td>v01</td>\n",
       "      <td>zUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fileID  start      end speaker label\n",
       "0  de2_e_b01_v0102301011114  524.4  939.798     v01   zUN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pre'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_seqs = padding not in ['None', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnnseg.data import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.array(np.rint((segments_arr[['start', 'end']] / datafile.offset)),\n",
    "                  dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52, 94]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bounds` were the boundaries in which there is voice in ms * 1000 / 10 (because the offset is 10), now corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats = [[-4.1554306e+02  6.9378067e+01  1.6545097e+01 ...  2.3677826e-01\n",
      "  -1.1491722e+00 -1.0111792e+00]\n",
      " [-4.1187183e+02  5.6095604e+01 -2.0172679e-01 ...  2.3677826e-01\n",
      "  -1.1491722e+00 -1.0111792e+00]\n",
      " [-4.1587122e+02  6.0025391e+01  9.4111891e+00 ...  2.3677826e-01\n",
      "  -1.1491722e+00 -1.0111792e+00]\n",
      " ...\n",
      " [-4.1675873e+02  5.5765411e+01  3.2940605e+00 ... -2.2276479e-01\n",
      "  -6.1275685e-01 -8.8081872e-01]\n",
      " [-4.2713913e+02  4.2217934e+01 -3.4910685e-01 ... -2.2276479e-01\n",
      "  -6.1275685e-01 -8.8081872e-01]\n",
      " [-4.2872861e+02  5.1364624e+01  1.3756428e+01 ... -2.2276479e-01\n",
      "  -6.1275685e-01 -8.8081872e-01]]\n",
      "feats shape is (149, 39)\n",
      "loop no. 0\n",
      "s = 52\n",
      "e = 94\n",
      "cutting to maximum length\n",
      "new_feats = [[-4.3935999e+02  3.8676880e+01  4.1746397e+00 ... -1.3803151e+00\n",
      "  -7.7529901e-01  1.0259549e-01]\n",
      " [-4.3328519e+02  5.8681412e+01  1.4759262e+01 ... -1.0292969e+00\n",
      "  -1.0466719e+00  4.4414034e-01]\n",
      " [-4.0103995e+02  8.3274643e+01  2.6987366e+01 ...  6.4401424e-01\n",
      "   8.8818264e-01  5.4182857e-01]\n",
      " ...\n",
      " [-3.7044510e+02  1.0567401e+02  3.3955765e+01 ...  1.0104920e-01\n",
      "  -1.5401207e-01  5.6449831e-01]\n",
      " [-3.7411316e+02  9.9037827e+01  3.1980671e+01 ... -5.0408220e-01\n",
      "   1.0673784e-01  9.2395109e-01]\n",
      " [-3.8897562e+02  9.1623596e+01  3.5974098e+01 ... -9.9924690e-01\n",
      "   3.4237463e-02  3.6131066e-01]]\n",
      "new_feats shape is (42, 39)\n",
      "length = 42\n",
      "before centering\n",
      "new_feats = [[-4.3935999e+02  3.8676880e+01  4.1746397e+00 ... -1.3803151e+00\n",
      "  -7.7529901e-01  1.0259549e-01]\n",
      " [-4.3328519e+02  5.8681412e+01  1.4759262e+01 ... -1.0292969e+00\n",
      "  -1.0466719e+00  4.4414034e-01]\n",
      " [-4.0103995e+02  8.3274643e+01  2.6987366e+01 ...  6.4401424e-01\n",
      "   8.8818264e-01  5.4182857e-01]\n",
      " ...\n",
      " [-3.7044510e+02  1.0567401e+02  3.3955765e+01 ...  1.0104920e-01\n",
      "  -1.5401207e-01  5.6449831e-01]\n",
      " [-3.7411316e+02  9.9037827e+01  3.1980671e+01 ... -5.0408220e-01\n",
      "   1.0673784e-01  9.2395109e-01]\n",
      " [-3.8897562e+02  9.1623596e+01  3.5974098e+01 ... -9.9924690e-01\n",
      "   3.4237463e-02  3.6131066e-01]]\n",
      "new_feats.mean = -5.705258369445801\n",
      "Are feats and mean the same? --> [[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "after centering\n",
      "new_feats = [[-433.65472     44.382137     9.879898  ...    4.3249435    4.9299593\n",
      "     5.8078537]\n",
      " [-427.57993     64.38667     20.46452   ...    4.6759615    4.6585865\n",
      "     6.149399 ]\n",
      " [-395.3347      88.979904    32.692623  ...    6.3492727    6.593441\n",
      "     6.247087 ]\n",
      " ...\n",
      " [-364.73984    111.37927     39.661022  ...    5.806308     5.551246\n",
      "     6.269757 ]\n",
      " [-368.4079     104.74309     37.68593   ...    5.201176     5.811996\n",
      "     6.6292095]\n",
      " [-383.27036     97.32886     41.679356  ...    4.7060113    5.7394958\n",
      "     6.066569 ]]\n",
      "creating mask with length of 42\n",
      "new_feats = [[-433.65472     44.382137     9.879898  ...    4.3249435    4.9299593\n",
      "     5.8078537]\n",
      " [-427.57993     64.38667     20.46452   ...    4.6759615    4.6585865\n",
      "     6.149399 ]\n",
      " [-395.3347      88.979904    32.692623  ...    6.3492727    6.593441\n",
      "     6.247087 ]\n",
      " ...\n",
      " [-364.73984    111.37927     39.661022  ...    5.806308     5.551246\n",
      "     6.269757 ]\n",
      " [-368.4079     104.74309     37.68593   ...    5.201176     5.811996\n",
      "     6.6292095]\n",
      " [-383.27036     97.32886     41.679356  ...    4.7060113    5.7394958\n",
      "     6.066569 ]]\n",
      "feats_split:\n",
      "[array([[-433.65472  ,   44.382137 ,    9.879898 , ...,    4.3249435,\n",
      "           4.9299593,    5.8078537],\n",
      "       [-427.57993  ,   64.38667  ,   20.46452  , ...,    4.6759615,\n",
      "           4.6585865,    6.149399 ],\n",
      "       [-395.3347   ,   88.979904 ,   32.692623 , ...,    6.3492727,\n",
      "           6.593441 ,    6.247087 ],\n",
      "       ...,\n",
      "       [-364.73984  ,  111.37927  ,   39.661022 , ...,    5.806308 ,\n",
      "           5.551246 ,    6.269757 ],\n",
      "       [-368.4079   ,  104.74309  ,   37.68593  , ...,    5.201176 ,\n",
      "           5.811996 ,    6.6292095],\n",
      "       [-383.27036  ,   97.32886  ,   41.679356 , ...,    4.7060113,\n",
      "           5.7394958,    6.066569 ]], dtype=float32)]\n",
      "\n",
      "\n",
      "feats length:\n",
      "1\n",
      "\n",
      "\n",
      "mask_split:\n",
      "[array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1.])]\n",
      "\n",
      "\n",
      "mask length:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "segments = \"wrd\"\n",
    "max_len = 1300\n",
    "padding = \"pre\"\n",
    "reverse = False\n",
    "normalize = False\n",
    "center = True\n",
    "with_deltas = True\n",
    "resample = None\n",
    "\n",
    "feats_split = []\n",
    "mask_split = []\n",
    "\n",
    "print(f\"feats = {datafile.feats}\")\n",
    "print(f\"feats shape is {datafile.feats.shape}\")\n",
    "\n",
    "for i in range(len(bounds)):\n",
    "    print(f\"loop no. {i}\")\n",
    "    s = bounds[i, 0]\n",
    "    e = bounds[i, 1]\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"e = {e}\")\n",
    "    \n",
    "    if max_len is not None:\n",
    "        print(\"cutting to maximum length\")\n",
    "        # cut features to maximum length\n",
    "        e = min(e, s + max_len)\n",
    "    new_feats = datafile.feats[s:e, :]\n",
    "    length = e - s\n",
    "    print(f\"new_feats = {new_feats}\")\n",
    "    print(f\"new_feats shape is {new_feats.shape}\")\n",
    "    print(f\"length = {length}\")\n",
    "    \n",
    "    \n",
    "    if resample and new_feats.shape[0] > 0:\n",
    "        print(\"resampling\")\n",
    "        length = resample\n",
    "        new_feats = scipy.signal.resample(new_feats, resample, axis=0)\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "\n",
    "    if not with_deltas:\n",
    "        print(\"cutting deltas\")\n",
    "        new_feats = new_feats[:, :datafile.n_coef]\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "\n",
    "    if normalize:\n",
    "        print(\"normalizing\")\n",
    "        maximum = new_feats.max()\n",
    "        minimum = new_feats.min()\n",
    "        diff = maximum - minimum\n",
    "        new_feats = (new_feats - minimum) / diff\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "    if center:\n",
    "        print(\"before centering\")\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "        print(f\"new_feats.mean = {new_feats.mean()}\")\n",
    "        print(f\"Are feats and mean the same? --> {new_feats == new_feats.mean()}\")\n",
    "        new_feats = new_feats - new_feats.mean()\n",
    "        print(\"after centering\")\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "\n",
    "    if not pad_seqs:\n",
    "        print(\"pad_seqs is None\")\n",
    "        new_feats = new_feats[None, ...]\n",
    "        mask = np.ones((1, length))\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "    else:\n",
    "        print(f\"creating mask with length of {length}\")\n",
    "        mask = np.ones(length)\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "\n",
    "    feats_split.append(new_feats)\n",
    "    mask_split.append(mask)\n",
    "    \n",
    "    print(\"feats_split:\")\n",
    "    print(feats_split)\n",
    "    print(\"\\n\")\n",
    "    print(\"feats length:\")\n",
    "    print(len(feats_split))\n",
    "    print(\"\\n\")\n",
    "    print(\"mask_split:\")\n",
    "    print(mask_split)\n",
    "    print(\"\\n\")\n",
    "    print(\"mask length:\")\n",
    "    print(len(mask_split))\n",
    "    \n",
    "\n",
    "if pad_seqs:\n",
    "    feats = pad_sequence(feats_split, padding=padding, reverse=reverse)\n",
    "    mask = pad_sequence(mask_split, padding=padding, reverse=reverse)\n",
    "else:\n",
    "    feats = feats_split\n",
    "    mask = mask_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 39), dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile.feats[500:502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 39)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile.feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile.n_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = datafile.feats - datafile.feats.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 39)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error causes found:\n",
    "\n",
    "1) `max_len` needs to be adapted to this material in config file. Originally it was 50, which yields an empty array at `segment_and_stack`. It was supposed to be the maximum syllable length in the material set.\n",
    "\n",
    "2) `self.bounds`, the boundaries in which there is voice in ms * 1000 / offset (offset is defined by `self.offset`), are yielding a slice of `self.features` that is empty. `self.features.shape` is `(149, 39)`, the boundaries are being set at over 5000 \n",
    "\n",
    "## to do:\n",
    "- find maximum syllable length in material set (`D:/MASTER/23-LIN-MaCL1/Modulpr√ºfung/dfc3sd.csv`)\n",
    "- set found length (in ms) in config file `max_len`\n",
    "- correct boundaries method to yield boundaries under 149 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 42, 39)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnnseg.backend import binary2integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2i = binary2integer(b=np.array([[True, True, False],[True, True, False]]), session=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum_3:0' shape=(2,) dtype=int32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with test:\n",
    "    b2i.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2i.value_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[True, True, False],[True, True, False]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ####### using method .inputs from AcousticDataset ###### \n",
      "\n",
      "\n",
      " ####### using method .segment_and_stack from AcousticDataset ###### \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATASET \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "reverse = False \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = True \n",
      "\n",
      "resample = None \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATAFILE: \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "padding = pre \n",
      "\n",
      "reverse = False \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = True \n",
      "\n",
      "resample = None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, x_mask = dataset.inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using method .targets from AcousticDataset\n",
      "\n",
      " ####### using method .segment_and_stack from AcousticDataset ###### \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATASET \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "reverse = True \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = False \n",
      "\n",
      "resample = None \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATAFILE: \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "padding = post \n",
      "\n",
      "reverse = True \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = False \n",
      "\n",
      "resample = None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(0, min(0 + 256, len(dataset.targets()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 56, 39)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [-3.90040466e+02,  8.03762512e+01,  1.63609600e+01, ...,\n",
       "          9.30139124e-01,  1.36380458e+00,  2.19446969e+00],\n",
       "        [-4.02878571e+02,  7.99380264e+01,  2.69165039e+01, ...,\n",
       "          2.31215739e+00,  2.40860820e+00,  1.80985677e+00],\n",
       "        [-4.19096375e+02,  6.18056870e+01,  2.19476452e+01, ...,\n",
       "          1.34008563e+00,  7.01640368e-01, -7.13101268e-01]],\n",
       "\n",
       "       [[-4.15527161e+02,  3.69979858e+01,  6.25174046e+00, ...,\n",
       "          1.53874552e+00,  2.88899809e-01, -3.28236490e-01],\n",
       "        [-4.22955078e+02,  3.70714722e+01,  1.10998583e+01, ...,\n",
       "          5.60496688e-01,  8.97203743e-01,  4.26920176e-01],\n",
       "        [-4.15920258e+02,  4.93633118e+01,  6.74550295e+00, ...,\n",
       "         -2.28527889e-01,  4.89172526e-02,  1.85603008e-01],\n",
       "        ...,\n",
       "        [-3.82517059e+02,  9.41860809e+01,  3.15595779e+01, ...,\n",
       "         -2.17247028e-02, -1.18375048e-01, -1.47884116e-01],\n",
       "        [-3.84195038e+02,  9.57783203e+01,  3.59547958e+01, ...,\n",
       "         -5.96632838e-01,  2.86293149e-01, -9.08593476e-01],\n",
       "        [-3.94542084e+02,  8.13721008e+01,  2.81547737e+01, ...,\n",
       "          5.25964320e-01,  1.23563385e+00, -9.09737051e-01]],\n",
       "\n",
       "       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [-3.97153137e+02,  8.12787018e+01,  2.21682129e+01, ...,\n",
       "         -8.10820758e-01, -3.42010856e-01,  6.02391437e-02],\n",
       "        [-3.94918671e+02,  8.47676849e+01,  2.39141922e+01, ...,\n",
       "         -1.40381920e+00, -2.96414942e-01,  1.67149648e-01],\n",
       "        [-4.05212280e+02,  7.27810898e+01,  9.42437840e+00, ...,\n",
       "         -9.75728691e-01, -2.91799039e-01, -2.90696502e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [-3.64409607e+02,  1.06514572e+02,  2.96083908e+01, ...,\n",
       "          1.57970667e+00,  5.06535061e-02,  2.03021720e-01],\n",
       "        [-3.53803619e+02,  1.08098633e+02,  2.66531086e+01, ...,\n",
       "          1.57970667e+00,  5.06535061e-02,  2.03021720e-01],\n",
       "        [-3.47703522e+02,  9.50632782e+01,  4.36449127e+01, ...,\n",
       "          1.57970667e+00,  5.06535061e-02,  2.03021720e-01]],\n",
       "\n",
       "       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [-3.92205688e+02,  8.53777771e+01,  2.78875847e+01, ...,\n",
       "          1.93573833e-01, -7.04476833e-01, -1.66865870e-01],\n",
       "        [-4.22584991e+02,  6.85737152e+01,  3.17524757e+01, ...,\n",
       "         -1.38375461e+00, -1.51154804e+00,  5.06290019e-01],\n",
       "        [-4.05633270e+02,  6.94728546e+01,  2.15529137e+01, ...,\n",
       "         -3.24397415e-01, -9.99894917e-01,  8.04879218e-02]],\n",
       "\n",
       "       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        ...,\n",
       "        [-4.14585327e+02,  7.89010391e+01,  2.75267029e+01, ...,\n",
       "          4.64178145e-01, -1.36755988e-01,  8.81241739e-01],\n",
       "        [-4.03210815e+02,  7.38143768e+01,  2.72295914e+01, ...,\n",
       "          1.37478083e-01, -5.56187749e-01,  9.39677179e-01],\n",
       "        [-4.08227631e+02,  6.47656250e+01,  1.92042809e+01, ...,\n",
       "         -3.15529287e-01, -2.29075804e-01,  4.88300979e-01]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mask[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ####### using method .segment_and_stack from AcousticDataset ###### \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATASET \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "reverse = False \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = True \n",
      "\n",
      "resample = None \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATAFILE: \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = None \n",
      "\n",
      "padding = pre \n",
      "\n",
      "reverse = False \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = True \n",
      "\n",
      "resample = None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, x_mask = dataset.segment_and_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 56, 39)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de2_e_b01_v0102301011111': <dnnseg.data.AcousticDatafile at 0x1ea60550518>,\n",
       " 'de2_e_b01_v0102301011112': <dnnseg.data.AcousticDatafile at 0x1ea60550438>,\n",
       " 'de2_e_b01_v0102301011113': <dnnseg.data.AcousticDatafile at 0x1ea60550160>,\n",
       " 'de2_e_b01_v0102301011114': <dnnseg.data.AcousticDatafile at 0x1ea60550978>,\n",
       " 'de2_e_b01_v0102301011115': <dnnseg.data.AcousticDatafile at 0x1ea604d8710>,\n",
       " 'de2_e_b01_v0102301011116': <dnnseg.data.AcousticDatafile at 0x1ea604aa1d0>,\n",
       " 'de2_e_b01_v0102301011117': <dnnseg.data.AcousticDatafile at 0x1ea5f34ecf8>}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_mask = datafile.segment_and_stack(padding=\"pre\", max_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30, 39)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ####### using method .segment_and_stack from AcousticDataset ###### \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATASET \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = 30 \n",
      "\n",
      "reverse = False \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = True \n",
      "\n",
      "resample = None \n",
      "\n",
      "ARGUMENTS PASSED TO METHOD SEGMENT_AND_STACK IN ACOUSTICDATAFILE: \n",
      "\n",
      "segments = wrd \n",
      "\n",
      "max_len = 30 \n",
      "\n",
      "padding = pre \n",
      "\n",
      "reverse = False \n",
      "\n",
      "normalize = False \n",
      "\n",
      "center = False \n",
      "\n",
      "with_deltas = True \n",
      "\n",
      "resample = None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, x_mask = dataset.segment_and_stack(max_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 30, 39)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnnseg",
   "language": "python",
   "name": "dnnseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
