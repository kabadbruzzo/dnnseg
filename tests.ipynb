{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = 'D:/results_bender/german_classify/classifications_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.dirname(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/results_bender/german_classify'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if foo:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if not n:\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e9cd9da6fc69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\dnnseg\\lib\\genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"
     ]
    }
   ],
   "source": [
    "os.path.exists(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'a': [2,3,1,5],\n",
    "    'b': [5,7,8,3],\n",
    "    'c': [8,4,6,5],\n",
    "    'd': [8,7,8,6],\n",
    "    'e': [1,1,1,1],\n",
    "    'f': [2,2,2,2],\n",
    "    'g': [4,5,6,7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c  d  e  f  g\n",
       "0  2  5  8  8  1  2  4\n",
       "1  3  7  4  7  1  2  5\n",
       "2  1  8  6  8  1  2  6\n",
       "3  5  3  5  6  1  2  7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = list(\"ade\")\n",
    "second = list(\"bcg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'd', 'e']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'd', 'e', 'b', 'c', 'g']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first + second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c  d  e  g\n",
       "0  2  5  8  8  1  4\n",
       "1  3  7  4  7  1  5\n",
       "2  1  8  6  8  1  6\n",
       "3  5  3  5  6  1  7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns.intersection(first+second)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = np.array([23, 12, 5, 19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test_numpy.txt', foo, fmt='%0.10g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 12  5 19]\n"
     ]
    }
   ],
   "source": [
    "print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 12,  5, 19])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_2 = pd.DataFrame(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_2.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do:\n",
    "\n",
    "- build dataset\n",
    "- test `AcousticDatafile(test.wav)` and `segments` method\n",
    "- test `AcousticDataset(directory)` and `segments` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnnseg.data import AcousticDatafile, AcousticDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:/model/german/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [x for x in os.listdir() if x.endswith(\".wav\")][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing file \"de2_e_b...\" 7/7       |    ETA - 0s     \n"
     ]
    }
   ],
   "source": [
    "dataset = AcousticDataset(\"D:/tests/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.labels(one_hot=False, segment_type='wrd').ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving issue in .inputs and .targets methods inside AcousticDataset class.\n",
    "Notes: `.inputs` and `.targets` only call `.segment_and_stack`, once as `padding = 'pre'` and once `padding = 'post'`\n",
    "# To do:\n",
    "- test `.segment_and_stack`from `AcousticDataset` outside of script \n",
    "- test `.inputs` and `.targets` outside of script\n",
    "- UNDERSTAND what this does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.segment_and_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = dataset.data[\"de2_e_b01_v0102301011114\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile.segment_and_stack(padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile.segment_and_stack(padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`segment_and_stack` method from AcousticDatafile"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    def segment_and_stack(\n",
    "            self,\n",
    "            segments='wrd',\n",
    "            max_len=None,\n",
    "            padding='pre',\n",
    "            reverse=False,\n",
    "            normalize=False,\n",
    "            center=False,\n",
    "            with_deltas=True,\n",
    "            resample=None\n",
    "    ):\n",
    "        assert not (normalize and center), 'normalize and center cannot both be true, since normalize constrains to the interval [0,1] and center recenters at 0.'\n",
    "        if isinstance(segments, str):\n",
    "        \n",
    "            if segments == 'vad':\n",
    "                segments_arr = self.vad_segments\n",
    "            elif segments == 'wrd':\n",
    "                segments_arr = self.wrd_segments\n",
    "            elif segments == 'phn':\n",
    "                segments_arr = self.phn_segments\n",
    "            elif segments == 'rnd':\n",
    "                segments_arr = self.rnd_segments\n",
    "            else:\n",
    "                raise ValueError('Segment type \"%s\" not recognized.' % segments)\n",
    "        else:\n",
    "            segments_arr = segments\n",
    "\n",
    "        #print(f\"Step 1: segments_arr is {segments_arr}\")\n",
    "\n",
    "        pad_seqs = padding not in ['None', None]\n",
    "\n",
    "        bounds = np.array(\n",
    "            np.rint((segments_arr[['start', 'end']] * 1000 / self.offset)),\n",
    "            dtype=np.int32\n",
    "        )\n",
    "\n",
    "        #print(f\"Step 2: boudnds is {bounds}\")\n",
    "        feats_split = []\n",
    "        mask_split = []\n",
    "        for i in range(len(bounds)):\n",
    "            s = bounds[i, 0]\n",
    "            e = bounds[i, 1]\n",
    "            if max_len is not None:\n",
    "                e = min(e, s + max_len)\n",
    "            new_feats = self.feats[s:e, :]\n",
    "            length = e - s\n",
    "            if resample and new_feats.shape[0] > 0:\n",
    "                length = resample\n",
    "                new_feats = scipy.signal.resample(new_feats, resample, axis=0)\n",
    "\n",
    "            if not with_deltas:\n",
    "                new_feats = new_feats[:, :self.n_coef]\n",
    "\n",
    "            if normalize:\n",
    "                maximum = new_feats.max()\n",
    "                minimum = new_feats.min()\n",
    "                diff = maximum - minimum\n",
    "                new_feats = (new_feats - minimum) / diff\n",
    "            if center:\n",
    "                new_feats = new_feats - new_feats.mean()\n",
    "\n",
    "            if not pad_seqs:\n",
    "                new_feats = new_feats[None, ...]\n",
    "                mask = np.ones((1, length))\n",
    "            else:\n",
    "                mask = np.ones(length)\n",
    "\n",
    "            feats_split.append(new_feats)\n",
    "            mask_split.append(mask)\n",
    "\n",
    "        if pad_seqs:\n",
    "            feats = pad_sequence(feats_split, padding=padding, reverse=reverse)\n",
    "            mask = pad_sequence(mask_split, padding=padding, reverse=reverse)\n",
    "        else:\n",
    "            feats = feats_split\n",
    "            mask = mask_split\n",
    "\n",
    "        return feats, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments passed during fitting:\n",
    "```\n",
    "segments = \"wrd\",\n",
    "max_len = 50,\n",
    "padding = \"pre\",\n",
    "reverse = False,\n",
    "normalize = False,\n",
    "center = True,\n",
    "with_deltas = True,\n",
    "resample = None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_arr = datafile.wrd_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_seqs = padding not in ['None', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnnseg.data import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.array(np.rint((segments_arr[['start', 'end']] / datafile.offset)),\n",
    "                  dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bounds` were the boundaries in which there is voice in ms * 1000 / 10 (because the offset is 10), now corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = \"wrd\"\n",
    "max_len = 1300\n",
    "padding = \"pre\"\n",
    "reverse = False\n",
    "normalize = False\n",
    "center = True\n",
    "with_deltas = True\n",
    "resample = None\n",
    "\n",
    "feats_split = []\n",
    "mask_split = []\n",
    "\n",
    "print(f\"feats = {datafile.feats}\")\n",
    "print(f\"feats shape is {datafile.feats.shape}\")\n",
    "\n",
    "for i in range(len(bounds)):\n",
    "    print(f\"loop no. {i}\")\n",
    "    s = bounds[i, 0]\n",
    "    e = bounds[i, 1]\n",
    "    print(f\"s = {s}\")\n",
    "    print(f\"e = {e}\")\n",
    "    \n",
    "    if max_len is not None:\n",
    "        print(\"cutting to maximum length\")\n",
    "        # cut features to maximum length\n",
    "        e = min(e, s + max_len)\n",
    "    new_feats = datafile.feats[s:e, :]\n",
    "    length = e - s\n",
    "    print(f\"new_feats = {new_feats}\")\n",
    "    print(f\"new_feats shape is {new_feats.shape}\")\n",
    "    print(f\"length = {length}\")\n",
    "    \n",
    "    \n",
    "    if resample and new_feats.shape[0] > 0:\n",
    "        print(\"resampling\")\n",
    "        length = resample\n",
    "        new_feats = scipy.signal.resample(new_feats, resample, axis=0)\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "\n",
    "    if not with_deltas:\n",
    "        print(\"cutting deltas\")\n",
    "        new_feats = new_feats[:, :datafile.n_coef]\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "\n",
    "    if normalize:\n",
    "        print(\"normalizing\")\n",
    "        maximum = new_feats.max()\n",
    "        minimum = new_feats.min()\n",
    "        diff = maximum - minimum\n",
    "        new_feats = (new_feats - minimum) / diff\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "    if center:\n",
    "        print(\"before centering\")\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "        print(f\"new_feats.mean = {new_feats.mean()}\")\n",
    "        print(f\"Are feats and mean the same? --> {new_feats == new_feats.mean()}\")\n",
    "        new_feats = new_feats - new_feats.mean()\n",
    "        print(\"after centering\")\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "\n",
    "    if not pad_seqs:\n",
    "        print(\"pad_seqs is None\")\n",
    "        new_feats = new_feats[None, ...]\n",
    "        mask = np.ones((1, length))\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "    else:\n",
    "        print(f\"creating mask with length of {length}\")\n",
    "        mask = np.ones(length)\n",
    "        print(f\"new_feats = {new_feats}\")\n",
    "\n",
    "    feats_split.append(new_feats)\n",
    "    mask_split.append(mask)\n",
    "    \n",
    "    print(\"feats_split:\")\n",
    "    print(feats_split)\n",
    "    print(\"\\n\")\n",
    "    print(\"feats length:\")\n",
    "    print(len(feats_split))\n",
    "    print(\"\\n\")\n",
    "    print(\"mask_split:\")\n",
    "    print(mask_split)\n",
    "    print(\"\\n\")\n",
    "    print(\"mask length:\")\n",
    "    print(len(mask_split))\n",
    "    \n",
    "\n",
    "if pad_seqs:\n",
    "    feats = pad_sequence(feats_split, padding=padding, reverse=reverse)\n",
    "    mask = pad_sequence(mask_split, padding=padding, reverse=reverse)\n",
    "else:\n",
    "    feats = feats_split\n",
    "    mask = mask_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile.feats[500:502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile.feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile.n_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = datafile.feats - datafile.feats.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error causes found:\n",
    "\n",
    "1) `max_len` needs to be adapted to this material in config file. Originally it was 50, which yields an empty array at `segment_and_stack`. It was supposed to be the maximum syllable length in the material set.\n",
    "\n",
    "2) `self.bounds`, the boundaries in which there is voice in ms * 1000 / offset (offset is defined by `self.offset`), are yielding a slice of `self.features` that is empty. `self.features.shape` is `(149, 39)`, the boundaries are being set at over 5000 \n",
    "\n",
    "## to do:\n",
    "- find maximum syllable length in material set (`D:/MASTER/23-LIN-MaCL1/Modulpr√ºfung/dfc3sd.csv`)\n",
    "- set found length (in ms) in config file `max_len`\n",
    "- correct boundaries method to yield boundaries under 149 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnnseg.backend import binary2integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2i = binary2integer(b=np.array([[True, True, False],[True, True, False]]), session=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with test:\n",
    "    b2i.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2i.value_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[True, True, False],[True, True, False]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_mask = dataset.inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(0, min(0 + 256, len(dataset.targets()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mask[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_mask = dataset.segment_and_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_mask = datafile.segment_and_stack(padding=\"pre\", max_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_mask = dataset.segment_and_stack(max_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do:\n",
    "- read sampa_to_ipa.csv correctly\n",
    "- change read method in plot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/model/german_sampa_to_ipa.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnnseg",
   "language": "python",
   "name": "dnnseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
